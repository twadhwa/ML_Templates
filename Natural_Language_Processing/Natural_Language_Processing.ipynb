{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing.ipynb",
      "provenance": [],
      "mount_file_id": "11zMbqrKK4XrCCi3ymjca7zComddqquQi",
      "authorship_tag": "ABX9TyMUXIc/X4CxkjGdacqcvIE1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twadhwa/ML_Templates/blob/main/Natural_Language_Processing/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO8En2JrDX3c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqex-AmDEj16"
      },
      "source": [
        "# Tsv = Tab Seperated Values \n",
        "# delimiter = default value is comma but we have to add \"\\t\"\n",
        "# quoting = 3 ignoring the quotes in the text \n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning Data Sets /Natural Language Processing /Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "iWBhiWwrEnWf",
        "outputId": "c797e92b-0146-4fa9-9b31-758230f0cd46"
      },
      "source": [
        "data "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Review  Liked\n",
              "0                             Wow... Loved this place.      1\n",
              "1                                   Crust is not good.      0\n",
              "2            Not tasty and the texture was just nasty.      0\n",
              "3    Stopped by during the late May bank holiday of...      1\n",
              "4    The selection on the menu was great and so wer...      1\n",
              "..                                                 ...    ...\n",
              "995  I think food should have flavor and texture an...      0\n",
              "996                           Appetite instantly gone.      0\n",
              "997  Overall I was not impressed and would not go b...      0\n",
              "998  The whole experience was underwhelming, and I ...      0\n",
              "999  Then, as if I hadn't wasted enough of my life ...      0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWqV4IAEGwHd"
      },
      "source": [
        "## Cleaning the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38V8KZ2PEpbb",
        "outputId": "fba09c12-ed47-446b-960b-ea410e56a345"
      },
      "source": [
        "import re\n",
        "# For removing words that are not useful for predicting the output \n",
        "import nltk  \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Remove words with similar meaning \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "\n",
        "# Iterating through all the reviews \n",
        "for i in range(0, 1000):\n",
        "  # Review is the cleaned review \n",
        "  # 1) Cleaning all puctuation \n",
        "  # sub is a function that can replace any thing you want by any thing you want \n",
        "  # We are replacing here the anything that is not a word with a space  \n",
        "  review = re.sub('[^a-zA-Z]', ' ', data['Review'][i])\n",
        "  # changing all capital letter to lower case \n",
        "  review = review.lower()\n",
        "  # Spliting the reviews in different word \n",
        "\n",
        "  review = review.split()\n",
        "  \n",
        "  ps = PorterStemmer()\n",
        "\n",
        "  # Specifying our stopwords \n",
        "  all_stopwords = stopwords.words('english')\n",
        "  \n",
        "  all_stopwords.remove('not')\n",
        "\n",
        "  # removing stop words \n",
        "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "  # Adding the words again \n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "  \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J50CO1Tofjee"
      },
      "source": [
        "## Creating bag of words models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrjFcU8mZxNS",
        "outputId": "ba37c940-115d-45f7-e307-41a92b028a79"
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# We still have words like name that do not have relevance for the result prediction \n",
        "# Max prediction will remove some extra words and convert 1566 to 1500 \n",
        "cv = CountVectorizer()\n",
        "# CV will give us the array of words just like hashing \n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "\n",
        "\n",
        "X.shape\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1566)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ic0FxUll_Rr"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtGQrbx9k12Y"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVlkF51_mE-t"
      },
      "source": [
        "## Training the Naive Bayes model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee4SWI3WmCQQ"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = GaussianNB()\n",
        "LR = LogisticRegression()\n",
        "Tree = RandomForestClassifier()\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KCE-YkRmRkC"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4oBuGHNmIqM"
      },
      "source": [
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "Tree.fit(X_train,y_train)\n",
        "LR.fit(X_train,y_train)\n",
        "y_LR = LR.predict(X_test)\n",
        "Y_Tree = Tree.predict(X_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZB0M17Ymbmg"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8txUfH1dmVam",
        "outputId": "d6803f1d-8b41-442d-fabb-7bc31c816377"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"With Naive baise \" , accuracy_score(y_test, y_pred))\n",
        "print(\"With Logistic Regression \" , accuracy_score(y_test, y_LR))\n",
        "print(\"With Random Forest \" , accuracy_score(y_test, Y_Tree))\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Naive baise  0.73\n",
            "With Logistic Regression  0.775\n",
            "With Random Forest  0.745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNsQxI2rmZrC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}